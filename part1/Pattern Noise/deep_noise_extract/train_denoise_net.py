# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E7m0EoAUNm8hn-rtemotVovsJVUjqLhS
"""

from torchvision.transforms import Normalize
import skimage.io
from skimage.transform import resize
import glob
from sklearn.metrics import roc_auc_score
from torchvision import transforms
import matplotlib.pyplot as plt
from torchvision import datasets
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from time import time
from sklearn.metrics import roc_curve, auc, precision_score,recall_score
import numpy as np
from PIL import Image
from facenet_pytorch import MTCNN
import numpy as np
import glob
from sklearn.metrics import roc_curve, auc
import numpy as np
import matplotlib.pyplot as plt

img_size = (220,220)
batch_size = 32
test_batch_size = 32
mean = [0, 0, 0]
std = [1, 1, 1]

lr=0.050
wd=0.0
decay_step=1
lr_decay=0.96
log_interval=200
num_epochs =11
epoch = 0
lam=1

neg=len(glob.glob('/kaggle/working/train/real/*.jpg'))
pos=len(glob.glob('/kaggle/working/train/fake/*.jpg'))
total=neg+pos


weight_for_0 = (1 / neg)*(total)/2.0 
weight_for_1 = (1 / pos)*(total)/2.0



transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean, std),

        ])


data_train_dir='/kaggle/working/train'

data_valid_dir='/kaggle/working/test'

dataset_train = datasets.ImageFolder(data_train_dir, transform=transform)
dataset_valid = datasets.ImageFolder(data_valid_dir, transform=transform)


train_loader = torch.utils.data.DataLoader(
    dataset_train,
    batch_size=batch_size, shuffle=True, num_workers=2,pin_memory=True,
)

valid_loader = torch.utils.data.DataLoader(
    dataset_valid,
    batch_size=test_batch_size, shuffle=False
)



if torch.cuda.is_available():
    
    device = torch.device('cuda')

loss_criterion = nn.BCELoss(reduce=False)
loss_criterion=loss_criterion.cuda()

loss_criterion2 = nn.L1Loss(size_average=True)
loss_criterion2=loss_criterion2.cuda()

classifier=classifier.cuda()

noise_net=noise_net.cuda()

params = list(classifier.parameters()) + list(net.parameters()) 
optimizer = optim.Adam(params, lr=lr, weight_decay=wd)
lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=decay_step, gamma=lr_decay)


def run_epoch(mode, data_loader, num_classes=1, optimizer=None, epoch=None, steps_per_epoch=None, loss_criterion=None):
    
    
    weight = torch.tensor([weight_for_0, weight_for_1]).cuda()

    pp=0
    tt_real=0
    tt_fake=0
    
    num_real=0
    num_fake=0

    yt=0
    
    tt=0   

    if mode == 'train':
        # program.requires_grad = True
        classifier.train()
        net.train()
    else:
        # program.requires_grad = False
        classifier.eval()
        net.eval()
        
    loss = 0.0
    y_true = None
    y_pred = None

    if steps_per_epoch is None:
        steps_per_epoch = len(data_loader)

    if epoch is not None:
        ite = tqdm(
            enumerate(data_loader, 0),
            total=steps_per_epoch,
            desc='Epoch {}: '.format(epoch)
        )
        
    else:
        ite = tqdm(enumerate(data_loader, 0))
        
        

    for i, data in ite:
        
        x = data[0].to(device)
        y = data[1].to(device)-1

        y[y==1]=2
        y[y==0]=1
        y[y==2]=0
        
        weight_ = weight[y.data.view(-1).long()].view_as(y)
        


        if mode == 'train':
            optimizer.zero_grad()

        if mode != 'train':
            with torch.no_grad():
                
                p = net(x)
                u = classifier(x-p)
                logits=torch.sigmoid(u)
        else:
            
            p = net(x)
            u = classifier(x-p)
            logits=torch.sigmoid(u)
        
        y = y.unsqueeze(1)
        y = y.float()
        
        
        if loss_criterion is not None:
            
    
            batch_loss = loss_criterion(logits, y)
            batch_loss = batch_loss * weight_
            batch_loss = batch_loss.mean() + 40* loss_criterion2(x,p)

            if mode == 'train':

                batch_loss.backward()
                optimizer.step()

            loss += batch_loss.item()


        if pp==0:
            
          yt=logits.cpu().detach().numpy()

        else:
            
          yt=np.concatenate((yt,logits.cpu().detach().numpy()),axis=0)
        
        pp=1
        

        logits[logits>=0.6]=1
        logits[logits<0.6]=0


        if y_true is None:
            y_true = y
        else:
            y_true = torch.cat([y_true, y], dim=0)
            
        
        
        for k in range(len(y)):
            if y[k].item()==1 and y[k].item()==logits[k].item():
                tt_fake+=1

            elif y[k].item()==0 and y[k].item()==logits[k].item():
                tt_real+=1    
        

        if i % log_interval == 0 and mode == 'train':

          print(epoch*steps_per_epoch + i)
          print("Loss at Step {} : {}".format(epoch*steps_per_epoch + i, loss/(i+1)))
        
        if i >= steps_per_epoch:
            break

    
    num_fake=torch.sum(y_true).item()
    num_real=y_true.shape[0]-num_fake

    accuracy_real= tt_real/(num_real)
    accuracy_fake= tt_fake/(num_fake)

    
    auc1= roc_auc_score(y_true.cpu().numpy(), yt)
    
    
    total_acc_frame=(accuracy_real+ 2 * accuracy_fake)/3

    if mode=='valid':
        
        fpr, tpr, _ = roc_curve(y_true.cpu().numpy(), yt)
        
        roc_auc = auc(fpr, tpr)
        plt.figure()
        lw = 2
        plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver operating characteristic')
        plt.legend(loc="lower right")
        plt.show()
        
    
        
    yt[yt>=0.6]=1
    yt[yt<0.6]=0
    
    p=precision_score(y_true.cpu().numpy(), yt)
    r=recall_score(y_true.cpu().numpy(), yt)  
        
        
        
        
    return {'accuracy real': accuracy_real ,'accuracy fake': accuracy_fake,'total_accuracy': total_acc_frame,
            'AUC': auc1,'precision' : p ,'recall' : r }


while epoch < num_epochs:
    train_metrics = run_epoch('train', train_loader, 1, optimizer, epoch=epoch, loss_criterion=loss_criterion)
    valid_metrics = run_epoch('valid', valid_loader, 1, epoch=epoch, loss_criterion=loss_criterion)
    print('Train Metrics : {}, Validation Metrics : {}'.format(str(train_metrics), str(valid_metrics)))
    print(epoch)
    epoch += 1
    lr_scheduler.step()